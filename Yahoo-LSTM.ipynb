{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version sys.version_info(major=3, minor=8, micro=5, releaselevel='final', serial=0)\n",
      "tf version 2.2.0 keras version 2.3.0-tf\n"
     ]
    }
   ],
   "source": [
    "print('python version', sys.version_info)\n",
    "print('tf version', tf.__version__, 'keras version', keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time_millis = lambda: int(round(time.time() * 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Source folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benchmark folders and file extensions\n",
      "../Stochastic-Methods/data/yahoo/dataset/ydata-labeled-time-series-anomalies-v1_0/A1Benchmark/ .. file extensions *.csv\n",
      "../Stochastic-Methods/data/yahoo/dataset/ydata-labeled-time-series-anomalies-v1_0/A2Benchmark/ .. file extensions *.csv\n",
      "../Stochastic-Methods/data/yahoo/dataset/ydata-labeled-time-series-anomalies-v1_0/A3Benchmark/ .. file extensions *TS*.csv\n",
      "../Stochastic-Methods/data/yahoo/dataset/ydata-labeled-time-series-anomalies-v1_0/A4Benchmark/ .. file extensions *TS*.csv\n"
     ]
    }
   ],
   "source": [
    "YAHOO_DS=\"../Stochastic-Methods/data/yahoo/dataset/ydata-labeled-time-series-anomalies-v1_0\"\n",
    "DIRS_FILE_EXTENSIONS = {'A1Benchmark' : \"*.csv\", \\\n",
    "                        'A2Benchmark' : \"*.csv\", \\\n",
    "                        'A3Benchmark' : \"*TS*.csv\", \\\n",
    "                        'A4Benchmark' : \"*TS*.csv\" }\n",
    "\n",
    "print(\"benchmark folders and file extensions\")\n",
    "for DIR, extension in DIRS_FILE_EXTENSIONS.items():\n",
    "    Benchmark_dir  = YAHOO_DS + os.path.sep + DIR + os.path.sep \n",
    "    print(\"{} .. file extensions {}\".format(Benchmark_dir, extension))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_with_labels(file, timeVariantColumns, labelColumnNum):\n",
    "    df = pd.read_csv(file)\n",
    "    data = df.values.astype('float64')\n",
    "    tsData = df[timeVariantColumns].values.astype('float64')\n",
    "    labels = data[:, labelColumnNum].reshape((-1,1))\n",
    "    tsDataWithLabels = np.hstack((tsData, labels))\n",
    "    return tsDataWithLabels, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(data):\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    scaler.fit(data)\n",
    "    return scaler, scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_set(dataset, split=0.67):\n",
    "    train_size = int(len(dataset) * split)\n",
    "    train, test = dataset[0:train_size, :], dataset[train_size:len(dataset), :]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input expected to be a 2D array with last column being label\n",
    "# Returns looked back X (n_samples, n_steps, n_features) and Y (n_samples, 2); \n",
    "# last column in looked back Y data returned is label\n",
    "# Only one step ahead prediction setting is expected.\n",
    "\n",
    "def look_back_and_create_dataset(tsDataWithLabels, look_back = 1):\n",
    "    lookbackTsDataX = [] \n",
    "    lookbackTsDataYAndLabel = []\n",
    "    for i in range(look_back, len(tsDataWithLabels)):\n",
    "        a = tsDataWithLabels[i-look_back:i, :-1]\n",
    "        lookbackTsDataX.append(a)\n",
    "        lookbackTsDataYAndLabel.append(tsDataWithLabels[i])\n",
    "    return np.array(lookbackTsDataX), np.array(lookbackTsDataYAndLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_validation(Xtrain, Ytrain, validation_ratio=0.1):\n",
    "    validation_size = int(len(Xtrain) * validation_ratio)\n",
    "    Xtrain, Xvalid = Xtrain[validation_size:], Xtrain[:validation_size]\n",
    "    Ytrain, Yvalid = Ytrain[validation_size:], Ytrain[:validation_size]\n",
    "    return Xtrain, Ytrain, Xvalid, Yvalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deviations(model, X, Y):\n",
    "    deviations = np.absolute(Y - model.predict(X))\n",
    "    print(\"Deviation Min {}, Max {}\".format(np.amin(deviations, axis=0), np.amax(deviations, axis=0)))    \n",
    "    return deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_records_above_deviation_pctile(model, X, Y, pctile=95):\n",
    "    deviations = get_deviations(model, X, Y)\n",
    "    pctileDeviationValue = np.percentile(deviations, q=pctile, axis=0)\n",
    "    print(\"Deviation {}th pctile {}\".format(pctile, pctileDeviationValue ))\n",
    "    labels = (deviations > pctileDeviationValue).astype('int')\n",
    "    print(\"Deviation > {}th pctile is_anomaly labels in data {}\".format(pctile, np.unique(labels, return_counts = True)))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_metrics(actual, predicted):\n",
    "    return confusion_matrix(actual, predicted), precision_score(actual, predicted), \\\n",
    "    recall_score(actual, predicted), f1_score(actual, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note here the slight change in how we stack the hidden LSTM layers - special for the last LSTM layer.\n",
    "def baseline_model(input_shape, learning_rate):\n",
    "    def build_model(input_shape=input_shape, n_hidden = 1, n_units = 50, learning_rate = learning_rate):\n",
    "        model = keras.models.Sequential()\n",
    "        model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "        for layer in range(n_hidden - 1):\n",
    "            # return sequence = true for all layers except last layer\n",
    "            model.add(keras.layers.LSTM(n_units, return_sequences = True, activation = 'relu'))\n",
    "        model.add(keras.layers.LSTM(n_units, activation = 'relu'))\n",
    "        model.add(keras.layers.Dense(1))\n",
    "        optimizer = keras.optimizers.Adam(lr=learning_rate)\n",
    "        model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "        return model\n",
    "    return build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_actuals_vs_predictions(Y, YtrainPredicted, YtestPredicted, look_back):\n",
    "    trainPredictPlot = np.empty_like(Y)\n",
    "    trainPredictPlot[:, :] = np.nan\n",
    "    trainPredictPlot[:len(YtrainPredicted), :] = YtrainPredicted\n",
    "    \n",
    "    testPredictPlot = np.empty_like(Y)\n",
    "    testPredictPlot[:, :] = np.nan\n",
    "    testPredictPlot[len(YtrainPredicted):len(Y), :] = YtestPredicted    \n",
    "\n",
    "    #Now Plot\n",
    "    plt.figure(figsize=(40,10))\n",
    "    plt.plot(testPredictPlot, label ='Test Prediction')\n",
    "    plt.plot(trainPredictPlot, label ='Train Prediction')\n",
    "    plt.plot(Y, label = 'Actual')\n",
    "    plt.legend((\"Test Prediction\", \"Train Prediction\", \"Actual\"), loc=3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The `perform_training_on_benchmark_directory` is a wrapper fucntion which calls data_read, look_back, split methords  \n",
    "\n",
    "Decription for each parameters\n",
    "\n",
    "    benchmark_dir             - The full path to a folder where the data resides. This will be the path to a A* Benchmark folders.\n",
    "    extension_pattern         - File name extension pattern for files of this folder.\n",
    "    timeVariantColumns        – The time variant column specifies a list of values that changes in time.  In case of Yahoo! It’s the “value” column.\n",
    "    labelColumnNum            – Specifies the column number which denotes if that record is anomaly or not.  The case of A1Benchmark and A2Benchmark folder the field is marked as “is_anomaly” whereas in case of A3Benchmark and A4Benchmark its “anomaly”\n",
    "    param_distribs             - Distribution of parameters to search for best model using randomized search.\n",
    "    files_to_process  - Specifies the number of files that needs to be processed per directory.  \n",
    "    plot_graph                          – Specifies to plot graph or not for each file.    \n",
    "    validation_ratio    - What fraction of Xtrain, Ytrain to be used for early stopping validation.\n",
    "    early_stop_patience - Stop optimizing after how many successive epochs without further loss reduction\n",
    "    epochs              - Total number of epochs to try and optimize loss.\n",
    "    batch_size          - Size of batches in each epoch\n",
    "    n_iter              - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do it on each benchmark directory files  \n",
    "def perform_training_on_benchmark_directory(benchmark_dir, extension, timeVariantColumns, \n",
    "                                            labelColumnNum, param_distribs, files_to_process = 'ALL', plot_graph = 1,\n",
    "                                            validation_ratio = 0.1, early_stop_patience = 5, epochs = 25, batch_size = 32,\n",
    "                                            n_iter = 1, cv = 3, verbosity = 0):\n",
    "    pctile = 99.5\n",
    "    split = 0.8\n",
    "    look_back = 24\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    Benchmark_dir  = YAHOO_DS + os.path.sep + benchmark_dir + os.path.sep \n",
    "    benchmark_files = glob.glob(Benchmark_dir + extension, recursive=True)\n",
    "    \n",
    "    if files_to_process == 'ALL' :\n",
    "        num_files_to_process = len(benchmark_files)\n",
    "    else :\n",
    "        num_files_to_process = files_to_process    \n",
    "    \n",
    "\n",
    "    resultsMap={} # results from this folder    \n",
    "    for file_name in benchmark_files[:num_files_to_process]:\n",
    "        keras.backend.clear_session()\n",
    "        print('File Name : ', file_name)\n",
    "        \n",
    "        # read data        \n",
    "        tsDataWithLabels, data = read_data_with_labels(file_name, timeVariantColumns, labelColumnNum)\n",
    "        print(\"Shapes: time variant data with labels {}, full data {}\".format(tsDataWithLabels.shape, data.shape))\n",
    "        \n",
    "        # scale data\n",
    "        scaler, tsDataScaled = scale(tsDataWithLabels) \n",
    "        \n",
    "        # Get look back data in the 3D array shape\n",
    "        lookbackX, lookbackY = look_back_and_create_dataset(tsDataScaled, look_back=look_back)\n",
    "        print(\"Look back data shapes: lookbackX {} lookbackY {}\".format(lookbackX.shape, lookbackY.shape))\n",
    "        \n",
    "        # split into train/test\n",
    "        Xtrain_full, Xtest = split_data_set(lookbackX, split=0.8)\n",
    "        Ytrain_full, Ytest = split_data_set(lookbackY[:, :-1], split=0.8)   # exclude labels     \n",
    "        \n",
    "        print(\"Shapes: Xtrain_full {}, Ytrain_full {}, Xtest {}, Ytest {}\".format(Xtrain_full.shape, Ytrain_full.shape, \n",
    "                                                                                  Xtest.shape, Ytest.shape))\n",
    "        \n",
    "        # split further full train set into train and validation set\n",
    "        Xtrain, Ytrain, Xvalid, Yvalid = get_train_validation(Xtrain_full, Ytrain_full, validation_ratio=0.1)\n",
    "\n",
    "        print(\"Shapes: Xtrain {}, Ytrain {}, Xvalid {}, Yvalid {}\".format(Xtrain.shape, Ytrain.shape, \n",
    "                                                                          Xvalid.shape, Yvalid.shape))\n",
    "        \n",
    "        \n",
    "        input_shape = (Xtrain.shape[1], Xtrain.shape[2])\n",
    "        regressor = keras.wrappers.scikit_learn.KerasRegressor(build_fn = baseline_model(input_shape=input_shape, \n",
    "                                                                                 learning_rate=learning_rate))\n",
    "\n",
    "        early_stopping_cb = keras.callbacks.EarlyStopping(patience=early_stop_patience, restore_best_weights = True)\n",
    "\n",
    "        rnd_search_cv = RandomizedSearchCV(regressor, param_distribs, n_iter = n_iter, cv = cv, verbose = verbosity)\n",
    "\n",
    "        start_millis = current_time_millis()\n",
    "        rnd_search_cv.fit(Xtrain, Ytrain, epochs=epochs, batch_size=batch_size, validation_data=(Xvalid, Yvalid), \n",
    "                          callbacks=[early_stopping_cb], verbose=verbosity)\n",
    "\n",
    "\n",
    "        end_millis = current_time_millis()\n",
    "\n",
    "        model = rnd_search_cv.best_estimator_.model\n",
    "        print(\"Best parameters {} best score {}:\".format(rnd_search_cv.best_params_, -rnd_search_cv.best_score_))\n",
    "\n",
    "        trainMSE = model.evaluate(Xtrain_full, Ytrain_full, verbose = verbosity)\n",
    "        print(\"Train Score: {0:.5f} MSE {1:.5f} RMSE\".format(trainMSE, np.sqrt(trainMSE)))\n",
    "        testMSE = model.evaluate(Xtest, Ytest, verbose = verbosity)\n",
    "        print(\"Test Score: {0:.5f} MSE {1:.5f} RMSE\".format(testMSE, np.sqrt(testMSE)))\n",
    "        \n",
    "                \n",
    "        \n",
    "        # get deviations for whole dataset and id records with deviations > pctile threshold and asign an is_anomaly label\n",
    "        predictedLabels = get_records_above_deviation_pctile(model, lookbackX, lookbackY[:, :-1], pctile)\n",
    "\n",
    "        # actual is_anomaly labels in dataset\n",
    "        actualLabels = (data[look_back:, labelColumnNum] != 0.0).astype('int')    \n",
    "        print(\"Actual is_anomaly labels in data\", np.unique(actualLabels, return_counts = True))\n",
    "\n",
    "        # Compare calculated labels and actual labels to find confusion matrix, precision, recall, and F1\n",
    "        conf_matrix, prec, recall, f1 = get_classification_metrics(actualLabels, predictedLabels)\n",
    "        print(\"Confusion matrix \\n{0}\\nprecision {1:.5f}, recall {2:.5f}, f1 {3:.5f}\".format(conf_matrix, prec, recall, f1))\n",
    "        print(\"Time to train: {} ms\".format(end_millis - start_millis))\n",
    "        resultsMap[file_name] = {'traintime' : (end_millis - start_millis), 'model' : model, \n",
    "                                'best params' : rnd_search_cv.best_params_, 'best score' : -rnd_search_cv.best_score_,\n",
    "                                'train MSE' : trainMSE, 'test MSE' : testMSE,\n",
    "                                'precision' : prec, 'recall' : recall, 'f1' : f1, 'confusion_matrix' : conf_matrix}\n",
    "         \n",
    "        \n",
    "    return resultsMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_summary_for_benchmark_folder(resultsMap, benchmark_folder):\n",
    "    precisions=[]\n",
    "    recalls=[]\n",
    "    f1s=[]\n",
    "    times = []\n",
    "    for v in resultsMap.values():\n",
    "        precisions.append(v['precision'])\n",
    "        recalls.append(v['recall'])\n",
    "        f1s.append(v['f1'])\n",
    "        times.append(v['traintime'])\n",
    "    avg_prec = np.average(np.array(precisions))\n",
    "    avg_recall = np.average(np.array(recalls))\n",
    "    avg_f1 = np.average(np.array(f1s))\n",
    "    avg_time = np.average(np.array(times))\n",
    "    print(benchmark_folder, \": Avg precision {0:.5f} recall {1:.5f} f1 {2:.5f} time to train {3:.2f} ms\".\n",
    "          format(avg_prec, avg_recall, avg_f1, avg_time))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs = {\n",
    "    \"n_hidden\": np.arange(1, 3).tolist(), # upto 2 hidden layers\n",
    "    \"n_units\": np.arange(5,6).tolist() # 5 hidden layer units/neurons\n",
    "}\n",
    "\n",
    "n_iter = 1\n",
    "cv = 5\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "early_stop_patience = 5\n",
    "verbosity = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Name :  ../Stochastic-Methods/data/yahoo/dataset/ydata-labeled-time-series-anomalies-v1_0/A1Benchmark/real_4.csv\n",
      "Shapes: time variant data with labels (1423, 2), full data (1423, 3)\n",
      "Look back data shapes: lookbackX (1399, 24, 1) lookbackY (1399, 2)\n",
      "Shapes: Xtrain_full (1119, 24, 1), Ytrain_full (1119, 1), Xtest (280, 24, 1), Ytest (280, 1)\n",
      "Shapes: Xtrain (1008, 24, 1), Ytrain (1008, 1), Xvalid (111, 24, 1), Yvalid (111, 1)\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.5653e-05\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 4.1792e-06\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.2219e-04\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 4.9889e-06\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.6740e-04\n",
      "Best parameters {'n_units': 5, 'n_hidden': 1} best score 6.288193608270377e-05:\n",
      "Train Score: 0.00006 MSE 0.00804 RMSE\n",
      "Test Score: 0.00722 MSE 0.08496 RMSE\n",
      "Deviation Min [3.6154951e-06], Max [1.02289911]\n",
      "Deviation 99.5th pctile [0.15381074]\n",
      "Deviation > 99.5th pctile is_anomaly labels in data (array([0, 1]), array([1392,    7]))\n",
      "Actual is_anomaly labels in data (array([0, 1]), array([1394,    5]))\n",
      "Confusion matrix \n",
      "[[1392    2]\n",
      " [   0    5]]\n",
      "precision 0.71429, recall 1.00000, f1 0.83333\n",
      "Time to train: 53479 ms\n",
      "File Name :  ../Stochastic-Methods/data/yahoo/dataset/ydata-labeled-time-series-anomalies-v1_0/A2Benchmark/synthetic_10.csv\n",
      "Shapes: time variant data with labels (1421, 2), full data (1421, 3)\n",
      "Look back data shapes: lookbackX (1397, 24, 1) lookbackY (1397, 2)\n",
      "Shapes: Xtrain_full (1117, 24, 1), Ytrain_full (1117, 1), Xtest (280, 24, 1), Ytest (280, 1)\n",
      "Shapes: Xtrain (1006, 24, 1), Ytrain (1006, 1), Xvalid (111, 24, 1), Yvalid (111, 1)\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0410\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0104\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1293\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0076\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0211\n",
      "Best parameters {'n_units': 5, 'n_hidden': 2} best score 0.041866316087543966:\n",
      "Train Score: 0.13046 MSE 0.36120 RMSE\n",
      "Test Score: 0.12573 MSE 0.35459 RMSE\n",
      "Deviation Min [0.0009927], Max [0.85502031]\n",
      "Deviation 99.5th pctile [0.65630195]\n",
      "Deviation > 99.5th pctile is_anomaly labels in data (array([0, 1]), array([1390,    7]))\n",
      "Actual is_anomaly labels in data (array([0, 1]), array([1393,    4]))\n",
      "Confusion matrix \n",
      "[[1388    5]\n",
      " [   2    2]]\n",
      "precision 0.28571, recall 0.50000, f1 0.36364\n",
      "Time to train: 102161 ms\n",
      "File Name :  ../Stochastic-Methods/data/yahoo/dataset/ydata-labeled-time-series-anomalies-v1_0/A3Benchmark/A3Benchmark-TS8.csv\n",
      "Shapes: time variant data with labels (1680, 2), full data (1680, 9)\n",
      "Look back data shapes: lookbackX (1656, 24, 1) lookbackY (1656, 2)\n",
      "Shapes: Xtrain_full (1324, 24, 1), Ytrain_full (1324, 1), Xtest (332, 24, 1), Ytest (332, 1)\n",
      "Shapes: Xtrain (1192, 24, 1), Ytrain (1192, 1), Xvalid (132, 24, 1), Yvalid (132, 1)\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0072\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2201\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0033\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0969\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0029\n",
      "Best parameters {'n_units': 5, 'n_hidden': 1} best score 0.06608604406937957:\n",
      "Train Score: 0.00304 MSE 0.05512 RMSE\n",
      "Test Score: 0.01036 MSE 0.10177 RMSE\n",
      "Deviation Min [9.4099008e-06], Max [0.27328163]\n",
      "Deviation 99.5th pctile [0.18917537]\n",
      "Deviation > 99.5th pctile is_anomaly labels in data (array([0, 1]), array([1647,    9]))\n",
      "Actual is_anomaly labels in data (array([0, 1]), array([1652,    4]))\n",
      "Confusion matrix \n",
      "[[1644    8]\n",
      " [   3    1]]\n",
      "precision 0.11111, recall 0.25000, f1 0.15385\n",
      "Time to train: 61171 ms\n",
      "File Name :  ../Stochastic-Methods/data/yahoo/dataset/ydata-labeled-time-series-anomalies-v1_0/A4Benchmark/A4Benchmark-TS20.csv\n",
      "Shapes: time variant data with labels (1680, 2), full data (1680, 9)\n",
      "Look back data shapes: lookbackX (1656, 24, 1) lookbackY (1656, 2)\n",
      "Shapes: Xtrain_full (1324, 24, 1), Ytrain_full (1324, 1), Xtest (332, 24, 1), Ytest (332, 1)\n",
      "Shapes: Xtrain (1192, 24, 1), Ytrain (1192, 1), Xvalid (132, 24, 1), Yvalid (132, 1)\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0143\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0260\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0121\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0246\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2545\n",
      "Best parameters {'n_units': 5, 'n_hidden': 1} best score 0.06629782170057297:\n",
      "Train Score: 0.01875 MSE 0.13693 RMSE\n",
      "Test Score: 0.01200 MSE 0.10953 RMSE\n",
      "Deviation Min [0.00014146], Max [0.5305528]\n",
      "Deviation 99.5th pctile [0.3304863]\n",
      "Deviation > 99.5th pctile is_anomaly labels in data (array([0, 1]), array([1647,    9]))\n",
      "Actual is_anomaly labels in data (array([0, 1]), array([1643,   13]))\n",
      "Confusion matrix \n",
      "[[1640    3]\n",
      " [   7    6]]\n",
      "precision 0.66667, recall 0.46154, f1 0.54545\n",
      "Time to train: 56480 ms\n",
      "Total Time to proces all the selected files : 282454 ms\n"
     ]
    }
   ],
   "source": [
    "#files_to_process = 'ALL'\n",
    "files_to_process = 1\n",
    "directoryResultsMap = {}\n",
    "start_millis = current_time_millis()\n",
    "for folder, extension in DIRS_FILE_EXTENSIONS.items():\n",
    "    timeVariantColumns = ['value']\n",
    "    labelColumnNum = 2\n",
    "    resultsMap = perform_training_on_benchmark_directory(folder, extension, timeVariantColumns, \n",
    "                                            labelColumnNum, param_distribs, files_to_process, plot_graph = 1, \n",
    "                                            early_stop_patience = 5, epochs = epochs, batch_size = batch_size,\n",
    "                                            n_iter = n_iter, cv = cv, verbosity = verbosity)\n",
    "    directoryResultsMap[folder] = resultsMap;\n",
    "    #print_summary_for_benchmark_folder(resultsMap, folder)\n",
    "end_millis = current_time_millis()\n",
    "print(\"Total Time to proces all the selected files : {} ms\".format(end_millis - start_millis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Statistics for each folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1Benchmark : Avg precision 0.71429 recall 1.00000 f1 0.83333 time to train 53479.00 ms\n",
      "A2Benchmark : Avg precision 0.28571 recall 0.50000 f1 0.36364 time to train 102161.00 ms\n",
      "A3Benchmark : Avg precision 0.11111 recall 0.25000 f1 0.15385 time to train 61171.00 ms\n",
      "A4Benchmark : Avg precision 0.66667 recall 0.46154 f1 0.54545 time to train 56480.00 ms\n"
     ]
    }
   ],
   "source": [
    "#finally Print summary for each directory\n",
    "for directory in directoryResultsMap.keys() :\n",
    "    print_summary_for_benchmark_folder(directoryResultsMap[directory], directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
